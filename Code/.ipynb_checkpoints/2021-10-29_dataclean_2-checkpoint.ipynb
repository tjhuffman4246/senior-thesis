{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Data Clean\n",
    "## Oct. 29, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from glob import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining files cleaned in Oct. 28 file into one long file, for both pitchers and hitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revises path to access the data we want\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_path = os.path.dirname(cwd) + '/Data/Clean'\n",
    "\n",
    "# Gets path for every data file we have\n",
    "\n",
    "all_csv_files = [file\n",
    "                 for path, subdir, files in os.walk(data_path)\n",
    "                 for file in glob(os.path.join(path, '*.csv'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Age', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'SB', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'MLB', 'Year', 'Level', 'Org']\n",
      "['Kirk Asche', '23', '16', '66', '56', '9', '12', '2', '0', '3', '5', '0', '0', '9', '16', '.214', '.333', '.411', '.744', '23', '0', '1', '0', '0', '0', '0', '2001', 'AA', 'OAK']\n",
      "['Caonabo Cosme', '22', '34', '108', '99', '9', '19', '2', '2', '0', '4', '1', '2', '4', '32', '.192', '.223', '.253', '.476', '25', '0', '0', '5', '0', '0', '0', '2001', 'AA', 'OAK']\n",
      "['Eddy Furniss*', '25', '38', '152', '132', '11', '33', '10', '2', '1', '13', '0', '0', '19', '43', '.250', '.349', '.379', '.727', '50', '2', '1', '0', '0', '0', '0', '2001', 'AA', 'OAK']\n",
      "['Esteban German', '23', '92', '414', '335', '79', '95', '20', '3', '6', '30', '31', '11', '63', '66', '.284', '.415', '.415', '.830', '139', '6', '12', '4', '0', '0', '1', '2001', 'AA', 'OAK']\n",
      "['Josh Hochgesang', '24', '83', '345', '303', '48', '70', '18', '3', '6', '33', '8', '3', '30', '84', '.231', '.320', '.370', '.689', '112', '2', '10', '1', '1', '1', '0', '2001', 'AA', 'OAK']\n",
      "['Rusty Keith', '23', '89', '343', '291', '39', '76', '20', '1', '3', '31', '1', '4', '46', '43', '.261', '.360', '.368', '.728', '107', '9', '0', '4', '2', '0', '0', '2001', 'AA', 'OAK']\n",
      "['Jacques Landry', '27', '134', '589', '506', '102', '122', '14', '4', '36', '95', '37', '7', '64', '184', '.241', '.341', '.498', '.839', '252', '4', '15', '0', '4', '2', '0', '2001', 'AA', 'OAK']\n",
      "['Mike Lockwood*', '24', '131', '559', '493', '71', '128', '36', '3', '6', '69', '9', '4', '49', '80', '.260', '.333', '.381', '.715', '188', '8', '8', '4', '5', '1', '0', '2001', 'AA', 'OAK']\n",
      "['Brian Luderer', '22', '86', '344', '307', '30', '79', '20', '1', '5', '34', '1', '1', '23', '49', '.257', '.314', '.378', '.691', '116', '10', '4', '6', '4', '1', '0', '2001', 'AA', 'OAK']\n",
      "['Ryan Ludwick', '22', '119', '512', '443', '82', '119', '23', '3', '25', '96', '9', '10', '56', '113', '.269', '.356', '.503', '.860', '223', '6', '7', '1', '5', '1', '1', '2001', 'AA', 'OAK']\n",
      "['Chris Madonna*', '28', '40', '130', '106', '21', '25', '2', '1', '4', '16', '0', '1', '17', '31', '.236', '.344', '.387', '.731', '41', '3', '2', '2', '3', '1', '0', '2001', 'AA', 'OAK']\n",
      "['Todd Mensik*', '26', '132', '571', '502', '69', '142', '35', '1', '21', '79', '0', '1', '60', '104', '.283', '.361', '.482', '.843', '242', '16', '4', '0', '5', '2', '0', '2001', 'AA', 'OAK']\n",
      "['Aaron Nieckula', '24', '12', '45', '39', '8', '15', '5', '0', '1', '10', '0', '0', '2', '7', '.385', '.432', '.590', '1.022', '23', '0', '2', '1', '1', '0', '0', '2001', 'AA', 'OAK']\n",
      "['Jay Pecci#', '24', '125', '547', '469', '72', '122', '31', '7', '3', '49', '16', '7', '42', '56', '.260', '.353', '.375', '.728', '176', '11', '26', '8', '2', '1', '0', '2001', 'AA', 'OAK']\n",
      "['Rafael Pujols', '23', '19', '65', '59', '5', '13', '3', '1', '0', '6', '0', '0', '4', '13', '.220', '.277', '.305', '.582', '18', '3', '1', '0', '1', '0', '0', '2001', 'AA', 'OAK']\n",
      "['Mandy Romero#', '33', '29', '117', '103', '12', '32', '8', '0', '1', '12', '0', '0', '11', '10', '.311', '.379', '.417', '.797', '43', '1', '1', '1', '1', '0', '1', '2001', 'AA', 'OAK']\n",
      "['Oscar Salazar', '23', '130', '579', '521', '75', '139', '31', '4', '18', '95', '10', '3', '49', '100', '.267', '.329', '.445', '.774', '232', '11', '2', '1', '6', '2', '1', '2001', 'AA', 'OAK']\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "\n",
    "# Loops over each file and adds a column for year, team, and level\n",
    "# Saves to \"Clean\" folder\n",
    "\n",
    "for path in all_csv_files:\n",
    "    \n",
    "    with open(path, 'r') as readFile:\n",
    "        reader = csv.reader(readFile)\n",
    "        \n",
    "        # Getting the year, level, and organization from the file path\n",
    "                         \n",
    "        year = re.search('pitch/(.+?)/', path).group(1) if 'pitch' in path else re.search('bat/(.+?)/', path).group(1)\n",
    "        level = re.search(f'{year}/(.+?)/', path).group(1)\n",
    "        org = re.search(f'{level}_(.+?)_', path).group(1)\n",
    "        \n",
    "        for idx, row in enumerate(reader):\n",
    "            \n",
    "            if idx == 0: # adds the column header if it's the first row\n",
    "                row_mod = row + ['Year', 'Level', 'Org']\n",
    "                \n",
    "            else: # otherwise adds the info we found above\n",
    "                row_mod = row + [year, level, org]\n",
    "                \n",
    "            lines.append(row_mod)\n",
    "            \n",
    "    with open(path.replace('Raw', 'Clean'), 'w') as writeFile:\n",
    "        \n",
    "        writer = csv.writer(writeFile)\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "    lines = [] # resets the list so that we don't keep appending more lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/default/Desktop/College/21-22/Schoolwork/Thesis/Research/Data/Clean/bat/2001/AA/2001_AA_OAK_bat_0.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_csv_files[6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
