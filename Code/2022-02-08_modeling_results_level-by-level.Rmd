---
title: 'Modeling and Figures: Level-by-Level'
author: "Tate Huffman"
date: "2/8/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(tidyverse)
library(optimr)
library(nloptr)
library(knitr)
library(kableExtra)
performance = read_csv('../Data/Clean/performance_min20.csv')

n_years <- 10  # maximum number of years for a player in the data
```

## Overview

This is part of a series of RMarkdown files that will break down the code contained in the document at the end of the fall. This file in particular will write the functions necessary to run the O'Flaherty and Siow model, run the model, and update the figures used in the thesis.

This differs from the file dated February 1, 2022 because this will instead be fitting a series of models that are each based on a one-step promotion sequence; e.g., fitting the model to Low-A to High-A promotions, or Double-A to Triple-A. This is done to both address possible noise and inaccuracy from the previous iteration of the model, and also to potentially explain some of its more noticeable disparities. For example, if predicted exit probabilities are significantly less accurate at lower-level sequences than at higher levels, it may serve as support for the idea that baseball's economic system is more taxing for lower-level players, in turn helping springboard into a discussion of baseball's labor economics in general, and MLB's antitrust exemption more specifically.

## Model Details

We want to minimize the objective function

$$Q = \sum_{i=1}^{20} [P_i - \pi_i(\Omega)]^2$$

with respect to the parameters of $\Omega$. The values of $i$ correspond to the exit or promotion of the individual in a given time period: for $1 \leq i \leq 10$, this denotes an exit in year $i$, and for $11 \leq i \leq 20$, this denotes a promotion of this person in year $i-10$ (e.g., $i=12$ means a promotion for the individual in year 2). $P_i$ is the observed probability of a worker exiting or being promoting in period $i$.

$\pi_i(\Omega)$ is the predicted probability of an exit or promotion in period $i$, where $\Omega = (\alpha, \tau, \theta_0, \mu, \sigma)$. These variables, respectively, correspond to: the probability of a Type A (able) worker producing a good signal; the probability of a Type B (unable) worker producing a good signal; the ex ante probability of a new worker being Type A; the mean of the worker promotion threshold $\theta_u$; and its standard deviation.

When simplified, we see the probability of an exit in period $i$ as

$$\pi_i = [\theta_0 \alpha^{i-1}(1-\alpha) + (1-\theta_0) \tau^{i-1}(1-\tau)] \int_{\theta (i-1,i-1)}^{1} g(\theta_u; \mu, \sigma) d\theta_u$$

and the probability of a promotion in period $i$ as

$$\pi_{i+10} = [\theta_0 \alpha^i + (1-\theta_0) \tau^i] \int_{\theta (i-1,i-1)}^{\theta (i,i)} g(\theta_u; \mu, \sigma) d\theta_u$$

where $g(\theta_u; \mu, \sigma)$ is the beta distribution of $\theta_u$. Additionally, $\theta(x,n)$ represents the probability of a worker producing $x$ good signals in $n$ periods, which by Bayes' rule can be represented as

$$\theta(x,n) = \frac{\theta_0 \alpha^x (1-\alpha)^{n-x}}{\theta_0 \alpha^x (1-\alpha)^{n-x} + (1-\theta_0) \tau^x (1-\tau)^{n-x}}$$

## Creating a New Data Source

In order to run the model on a level-by-level basis, we need to replicate code from the February 1, 2022 file that computes promotion and exit probabilities, but doing so by minor league level. The code for this is below; the level to model can be changed by altering the leading variable that corresponds to the level used.

```{r setup_level}

# Setting up data for the level we're looking at

level_num <- 3 # 1 corresponds to Rookie, 2 to Short-Season-A, ..., 7 to MLB

# Performance filter

performance_filtered <- performance %>% 
  group_by(Name) %>% 
  mutate(max_level_sofar = if_else(yr_unique == 1, 
                                   0, # max level is 0 if this is first year in system
                                   cummax(level_high))) %>% 
  ungroup() %>% 
  filter(level_low == level_num, # lowest level this year is the level in question
         max_level_sofar <= level_num) %>% # hasn't played above this level
  group_by(Name) %>% 
  # we're interested whether people exit or are promoted FROM THE GIVEN LEVEL
  mutate(ever_exit = if_else(max(exit) == 1, 1, 0)) %>% 
  ungroup()

# Total number of players

n_total <- performance_filtered %>% 
  select(Name) %>% 
  pull() %>% 
  unique() %>% 
  length()

```

This computes the exit distribution for all player seasons that started at the assigned level.

```{r exits}

exit_distr_filtered <- performance_filtered %>%  
  group_by(Name, is_pitcher) %>% 
  summarise(n_year = yr_unique,
            is_pitcher = is_pitcher,
            ever_exit = ever_exit) %>% # whether player ever exits from this level
  group_by(ever_exit, n_year, is_pitcher) %>% # in case batter and pitcher have same name
  summarise(n_players = n_distinct(Name)) %>% 
  ungroup() %>% 
  group_by(ever_exit, n_year) %>% 
  summarise(n_players = sum(n_players)) %>% 
  ungroup()

# in the case where there's values for years 1-10 in the data
# adds row for players who never exit (i.e., have 10+ year careers)

# exit_distr_filtered <- exit_distr_filtered %>% 
  # add_row(ever_exit = 0,
  #         n_year = max((pull(select(filter(., ever_exit == 0), n_year)))),
  #         n_players = sum(pull(select(filter(., ever_exit == 0), n_players)))) %>%
  # tail(n = max(.$n_year) + 1) %>%
  # mutate(pct = n_players / n_total)

# in the case where there are some values missing
# from https://stackoverflow.com/questions/55064337/fill-in-missing-rows-in-r-data-frame 

exit_distr_filtered <- exit_distr_filtered %>% 
  group_by(ever_exit) %>% 
  mutate(yr_low = 1, yr_high = 10) %>% 
  select(-n_year, -n_players) %>% 
  distinct() %>% 
  expand(n_year = 1:10, yr_low) %>% 
  select(-yr_low) %>% 
  left_join(exit_distr_filtered,
            by = c("ever_exit", "n_year")) %>% 
  replace(is.na(.), 0) %>% 
  ungroup() %>% 
  add_row(ever_exit = 0,
          n_year = max((pull(select(filter(., ever_exit == 0), n_year)))),
          n_players = sum(pull(select(filter(., ever_exit == 0), n_players)))) %>% 
  tail(n = max(.$n_year) + 1) %>% 
  mutate(pct = n_players / n_total)

```

```{r promotions}

promote_distr_filtered <- performance_filtered %>% 
  group_by(yr_unique) %>% 
  summarize(n_players = sum(promotion),
            pct = n_players / n_total)

# Similar stuff as above for filling in missing columns with zero

promote_distr_filtered <- promote_distr_filtered %>% 
  mutate(val = TRUE) %>% 
  group_by(val) %>% 
  mutate(yr_low = 1, yr_high = 10) %>% 
  select(-yr_unique, -n_players, -pct) %>% 
  distinct() %>% 
  expand(yr_unique = 1:10, yr_low) %>% 
  select(-yr_low) %>% 
  left_join(promote_distr_filtered,
            by = c("yr_unique")) %>%
  replace(is.na(.), 0) %>%
  ungroup() %>% 
  select(-val)

```

```{r player_mvmt}

player_mvmt_filtered <- exit_distr_filtered %>% 
  filter(ever_exit == 1) %>%
  # add_row(ever_exit = 1,
  #         n_year = (max(.$n_year)+1):10, # if there are anomalies, fill w/ blank rows
  #         n_players = 0,
  #         pct = 0) %>% 
  select(pct) %>%
  bind_rows(promote_distr_filtered %>% select(pct)) %>%
  mutate(pct = pct / sum(.$pct), # normalizing to sum to 1 - probably not accurate?
         year = rep(seq(1:10), 2),
         exit = c(rep(T, 10), rep(F, 10)),
         cell = seq(1:20))

```

## Model Application

From above, actually running the model for this thesis requires the computation of a few integrals, in addition to minimizing the objective function $Q$ with respect to the parameters of $\Omega$. Functions for these computations are below.

```{r model_fns}

# Want to define the function pi_i(omega) that can calculate it for each value of i

# Calculating bounds for the beta density integral

theta_bounds <- function(n, theta_0, alpha, tau){
  
  # n <- theta_inputs[1]
  # theta_0 <- theta_inputs[2]
  # alpha <- theta_inputs[3]
  # tau <- theta_inputs[4]

  num <- theta_0*(alpha^n)
  den <- theta_0*(alpha^n) + (1-theta_0)*(tau^n)
    
  return(num / den)
}

# Calculating the beta density integral
# Bounds change depending on whether it's an entry or exit

beta_integral <- function(exit, n, a, b, theta_0, alpha, tau){
  
  # exit <- beta_inputs[1]
  # n <- beta_inputs[2]
  # a <- beta_inputs[3]
  # b <- beta_inputs[4]
  # theta_0 <- beta_inputs[5]
  # alpha <- beta_inputs[6]
  # tau <- beta_inputs[7]
  
  bound_lower <- theta_bounds(n-1, theta_0, alpha, tau)
  bound_upper <- if_else(exit, 1, theta_bounds(n, theta_0, alpha, tau))
  
  integrand <- function(x){
    
    num <- (x^(a-1)) * ((1-x)^(b-1))
    den <- beta(a, b)
    
    return(num / den)
  }
  
  return(integrate(integrand, lower = bound_lower, upper = bound_upper)$value)
}

# Gets the multiplication term

mult_term <- function(exit, n, theta_0, alpha, tau){
  
  # exit <- mult_inputs[1]
  # n <- mult_inputs[2]
  # theta_0 <- mult_inputs[3]
  # alpha <- mult_inputs[4]
  # tau <- mult_inputs[5]
  
  val <- if_else(exit, 
                 theta_0*(alpha^(n-1))*(1-alpha) + (1-theta_0)*(tau^(n-1))*(1-tau),
                 theta_0*(alpha^n) + (1-theta_0)*(tau^n))
  
  return(val)
}

# Main function to optimize, using functions created above

fn_optim <- function(input_vals){ # making this a vector for optimization
  
  a <- input_vals[1]
  b <- input_vals[2]
  theta_0 <- input_vals[3]
  alpha <- input_vals[4]
  tau <- input_vals[5]
  
  fn_val <- 0
  
  for(i in 1:(2*n_years)){ # USE YEAR INSTEAD OF CELL!
    
    # Filtering the observed data to the cell in question
    
    data <- player_mvmt_filtered %>% 
      filter(cell == i)
    
    # Isolating variables for ease of use
    
    obsv <- data$pct # observed probability
    cell <- data$cell # cell index
    yr <- data$year # year of the data
    exit <- data$exit # whether it's an exit period
    
    # Value for predicted probability
    
    add_val <- mult_term(exit, yr, theta_0, alpha, tau) * 
      beta_integral(exit, yr, a, b, theta_0, alpha, tau)
    
    fn_val <- fn_val + (obsv - add_val)^2
  }
  
  return(fn_val)
}

# Inequality function

fn_ineq <- function(input_vals){
  
  # Original constraint in 1.9 of O'Flaherty/Siow
  # return(1 - (((input_vals[5] / input_vals[4])^(n_years-1)) * (1-input_vals[5]) / (1 - input_vals[4]))) 
  
  # Modified constraint in 1.9 of O'Flaherty/Siow
  return(((1-input_vals[3])/input_vals[3]) * (input_vals[5]/input_vals[4]) * ((1-input_vals[4])/(1-input_vals[5])) - (1 - (input_vals[1]/(input_vals[1]+input_vals[2]))))
  
  # Ensures that alpha >= tau
  # return(input_vals[5] - input_vals[4]) 
  
}

```

After declaring these functions, we want to actually run the model. We do so by creating a set of initial guess parameters, which have upper and lower sanity-check bounds (to be altered?). The version run here works off of these constraints, and commented out is an unconstrained version that is less accurate but is retained for potential use.

```{r run_model}

# Initial guesses for parameter values and their respective bounds
# theta_0, alpha, tau, a, b
# a, b, theta_0, alpha, tau

init_guess <- c(2, 2, 0.1, 0.1, 0.1)
param_bounds_low <- c(0, 0, 0, 0, 0)
param_bounds_high <- c(Inf, Inf, 1, 1, 1)

# init_guess <- c(0.1, 0.6, 0.5, 2, 2)
# param_bounds_low <- c(0.05, 0.25, 0.24, 1, 1)
# param_bounds_high <- c(0.2, 0.95, 0.94, Inf, Inf)

# Getting some results!

# Unconstrained optimization

# results <- optim(init_guess, fn_optim,
#                  lower = param_bounds_low,
#                  upper = param_bounds_high,
#                  method = "L-BFGS-B")

# Constrained optimization

results <- nloptr(x0 = init_guess,
                  eval_f = fn_optim,
                  eval_g_ineq = fn_ineq,
                  lb = param_bounds_low,
                  ub = param_bounds_high,
                  opts = list("algorithm" = "NLOPT_LN_COBYLA",
                              "xtol_rel" = 1.0e-8))

# Getting the parameters from our calculations

params <- results$solution
a_pred <- params[1]
b_pred <- params[2]
theta_0_pred <- params[3]
alpha_pred <- params[4]
tau_pred <- params[5]

# theta_0_pred <- params[1]
# alpha_pred <- params[2]
# tau_pred <- params[3]
# a_pred <- params[4]
# b_pred <- params[5]

```

## Figures

We now want to examine how accurate these predictions are. First, we add the above info to the player movement table, and then we use `ggplot` to examine it visually.

```{r figures}

# Adding predicted percent of players falling into cell

# LOOK AT THIS AGAIN - ARE WE SURE IT'S 100% CORRECT?

player_mvmt_filtered <- player_mvmt_filtered %>% 
  rowwise() %>% # applying the model row-by-row
  mutate(pred_pct = mult_term(exit, year, theta_0_pred, alpha_pred, tau_pred) * 
           beta_integral(exit, year, a_pred, b_pred, 
                         theta_0_pred, alpha_pred, tau_pred)) %>% 
  ungroup() %>% 
  pivot_longer(cols = ends_with("pct"),
               names_to = "observed",
               values_to = "pct") %>% 
  mutate(observed = if_else(str_detect(observed, "pred"), F, T))
         # pct = if_else((!exit & !observed), pct*n_promotions, pct)) # times omitted promotes

# Exit probability

player_mvmt_filtered %>% 
  filter(exit) %>% 
  ggplot() +
  aes(x = year, y = 100*pct, color = observed) +
  geom_line() +
  scale_x_continuous(breaks = seq(0,10,2)) +
  scale_y_continuous(breaks = seq(0,30,5)) +
  scale_color_manual(name = "Probability",
                     labels = c("Predicted", "Observed"),
                     values = c("red", "blue")) +
  labs(x = "Number of Seasons Played",
       y = "Exit Probability (Percent)",
       caption = "Levels: Rookie through MLB") +
  theme_classic()

# Promotion probability

player_mvmt_filtered %>% 
  filter(!exit) %>% 
  ggplot() +
  aes(x = year, y = 100*pct, color = observed) +
  geom_line() +
  scale_x_continuous(breaks = seq(0,10,2)) +
  scale_y_continuous(breaks = seq(0,30,5)) +
  scale_color_manual(name = "Probability",
                     labels = c("Predicted", "Observed"),
                     values = c("red", "blue")) +
  labs(x = "Number of Seasons Played",
       y = "Promotion Probability (Percent)",
       caption = "Levels: Rookie through MLB") +
  theme_classic()

# Comparing observed exit and promotion probabilities

player_mvmt_filtered %>% 
  filter(observed) %>% 
  ggplot() +
  aes(x = year, y = 100*pct, color = exit) +
  geom_line() +
  scale_x_continuous(breaks = seq(0,10,2)) +
  scale_y_continuous(breaks = seq(0,30,5)) +
  scale_color_manual(name = "Probability",
                     labels = c("Promotion", "Exit"),
                     values = c("red", "blue")) +
  labs(x = "Number of Seasons Played",
       y = "Probability (Percent)",
       caption = "Levels: Rookie through MLB") +
  theme_classic()

# Comparing predicted exit and promotion probabilities

player_mvmt_filtered %>% 
  filter(!observed) %>% 
  ggplot() +
  aes(x = year, y = 100*pct, color = exit) +
  geom_line() +
  scale_x_continuous(breaks = seq(0,10,2)) +
  scale_y_continuous(breaks = seq(0,30,5)) +
  scale_color_manual(name = "Probability",
                     labels = c("Promotion", "Exit"),
                     values = c("red", "blue")) +
  labs(x = "Number of Seasons Played",
       y = "Probability (Percent)",
       caption = "Levels: Rookie through MLB") +
  theme_classic()

```

```{r save_results}

player_mvmt_filtered %>% 
  select(-cell) %>% 
  write_csv("../Scratch/2022-02-11 Results/AAA/2022-02-11_result_probs_aaa.csv")

```

